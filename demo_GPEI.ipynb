{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import exp10\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, mean_squared_error\n",
    "\n",
    "from spearmint.search import GPEISklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: SVM for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration (1/100) with score: 0.62740.\n",
      "Iteration (2/100) with score: 0.97719.\n",
      "Iteration (3/100) with score: 0.63091.\n",
      "Iteration (4/100) with score: 0.97544.\n",
      "Iteration (5/100) with score: 0.95788.\n",
      "Iteration (6/100) with score: 0.62740.\n",
      "Iteration (7/100) with score: 0.96491.\n",
      "Iteration (8/100) with score: 0.97018.\n",
      "Iteration (9/100) with score: 0.97016.\n",
      "Iteration (10/100) with score: 0.97544.\n",
      "Iteration (11/100) with score: 0.95083.\n",
      "Iteration (12/100) with score: 0.62740.\n",
      "Iteration (13/100) with score: 0.97368.\n",
      "Iteration (14/100) with score: 0.63091.\n",
      "Iteration (15/100) with score: 0.97368.\n",
      "Iteration (16/100) with score: 0.97368.\n",
      "Iteration (17/100) with score: 0.97193.\n",
      "Iteration (18/100) with score: 0.97368.\n",
      "Iteration (19/100) with score: 0.97193.\n",
      "Iteration (20/100) with score: 0.97368.\n",
      "Iteration (21/100) with score: 0.97368.\n",
      "Iteration (22/100) with score: 0.97368.\n",
      "Iteration (23/100) with score: 0.62740.\n",
      "Iteration (24/100) with score: 0.97368.\n",
      "Iteration (25/100) with score: 0.96488.\n",
      "Iteration (26/100) with score: 0.95611.\n",
      "Iteration (27/100) with score: 0.97368.\n",
      "Iteration (28/100) with score: 0.97544.\n",
      "Iteration (29/100) with score: 0.95963.\n",
      "Iteration (30/100) with score: 0.97016.\n",
      "Iteration (31/100) with score: 0.97368.\n",
      "Iteration (32/100) with score: 0.97544.\n",
      "Iteration (33/100) with score: 0.97544.\n",
      "Iteration (34/100) with score: 0.97544.\n",
      "Iteration (35/100) with score: 0.97542.\n",
      "Iteration (36/100) with score: 0.97016.\n",
      "Iteration (37/100) with score: 0.97367.\n",
      "Iteration (38/100) with score: 0.95962.\n",
      "Iteration (39/100) with score: 0.97719.\n",
      "Iteration (40/100) with score: 0.97542.\n",
      "Iteration (41/100) with score: 0.97719.\n",
      "Iteration (42/100) with score: 0.97718.\n",
      "Iteration (43/100) with score: 0.97719.\n",
      "Iteration (44/100) with score: 0.97718.\n",
      "Iteration (45/100) with score: 0.97719.\n",
      "Iteration (46/100) with score: 0.97718.\n",
      "Iteration (47/100) with score: 0.97718.\n",
      "Iteration (48/100) with score: 0.97542.\n",
      "Iteration (49/100) with score: 0.97368.\n",
      "Iteration (50/100) with score: 0.97544.\n",
      "Iteration (51/100) with score: 0.96842.\n",
      "Iteration (52/100) with score: 0.97367.\n",
      "Iteration (53/100) with score: 0.97719.\n",
      "Iteration (54/100) with score: 0.97544.\n",
      "Iteration (55/100) with score: 0.97895.\n",
      "Iteration (56/100) with score: 0.98070.\n",
      "Iteration (57/100) with score: 0.97719.\n",
      "Iteration (58/100) with score: 0.97895.\n",
      "Iteration (59/100) with score: 0.98070.\n",
      "Iteration (60/100) with score: 0.98070.\n",
      "Iteration (61/100) with score: 0.98070.\n",
      "Iteration (62/100) with score: 0.98070.\n",
      "Iteration (63/100) with score: 0.98070.\n",
      "Iteration (64/100) with score: 0.98070.\n",
      "Iteration (65/100) with score: 0.98070.\n",
      "Iteration (66/100) with score: 0.98070.\n",
      "Iteration (67/100) with score: 0.98070.\n",
      "Iteration (68/100) with score: 0.98070.\n",
      "Iteration (69/100) with score: 0.98070.\n",
      "Iteration (70/100) with score: 0.98070.\n",
      "Iteration (71/100) with score: 0.98070.\n",
      "Iteration (72/100) with score: 0.98070.\n",
      "Iteration (73/100) with score: 0.98070.\n",
      "Iteration (74/100) with score: 0.98070.\n",
      "Iteration (75/100) with score: 0.98070.\n",
      "Iteration (76/100) with score: 0.98070.\n",
      "Iteration (77/100) with score: 0.98070.\n",
      "Iteration (78/100) with score: 0.98070.\n",
      "Iteration (79/100) with score: 0.98070.\n",
      "Iteration (80/100) with score: 0.98070.\n",
      "Iteration (81/100) with score: 0.98070.\n",
      "Iteration (82/100) with score: 0.98070.\n",
      "Iteration (83/100) with score: 0.98070.\n",
      "Iteration (84/100) with score: 0.98070.\n",
      "Iteration (85/100) with score: 0.98070.\n",
      "Iteration (86/100) with score: 0.98070.\n",
      "Iteration (87/100) with score: 0.98070.\n",
      "Iteration (88/100) with score: 0.98070.\n",
      "Iteration (89/100) with score: 0.98070.\n",
      "Iteration (90/100) with score: 0.98070.\n",
      "Iteration (91/100) with score: 0.98070.\n",
      "Iteration (92/100) with score: 0.98070.\n",
      "Iteration (93/100) with score: 0.98070.\n",
      "Iteration (94/100) with score: 0.98070.\n",
      "Iteration (95/100) with score: 0.98070.\n",
      "Iteration (96/100) with score: 0.98070.\n",
      "Iteration (97/100) with score: 0.98070.\n",
      "Iteration (98/100) with score: 0.98070.\n",
      "Iteration (99/100) with score: 0.98070.\n",
      "Iteration (100/100) with score: 0.98070.\n",
      "Search completed in -170.38 seconds, with best score: 0.98070.\n",
      "Best parameters: C = 4.52446 gamma = 0.30881\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>gamma</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.627403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.977193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65536.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.630911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65536.000000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.975439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55726.768343</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.957879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.015625</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.627403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1139.910900</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>65536.000000</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.970175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>245.293265</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.970160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>65536.000000</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.975439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2588.020664</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.950831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.031601</td>\n",
       "      <td>0.627403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>836.440299</td>\n",
       "      <td>0.009000</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.001983</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.630911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>289.796079</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>108.830389</td>\n",
       "      <td>0.026219</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5148.186753</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.971930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>67.349946</td>\n",
       "      <td>0.007772</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>105.806104</td>\n",
       "      <td>0.014131</td>\n",
       "      <td>0.971930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>65536.000000</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>136.361171</td>\n",
       "      <td>0.014789</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1341.848828</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>19.188037</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.627403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12663.824966</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>65536.000000</td>\n",
       "      <td>0.109173</td>\n",
       "      <td>0.964881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9220.983302</td>\n",
       "      <td>0.052436</td>\n",
       "      <td>0.956109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3612.609660</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.973684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>39.023960</td>\n",
       "      <td>0.022473</td>\n",
       "      <td>0.975439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>65536.000000</td>\n",
       "      <td>0.025327</td>\n",
       "      <td>0.959634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>24212.033530</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.970160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2.495015</td>\n",
       "      <td>0.384285</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2.505270</td>\n",
       "      <td>0.385631</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2.429467</td>\n",
       "      <td>0.394208</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2.423513</td>\n",
       "      <td>0.394122</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2.403212</td>\n",
       "      <td>0.388294</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2.393544</td>\n",
       "      <td>0.395983</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2.475230</td>\n",
       "      <td>0.387386</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>2.419199</td>\n",
       "      <td>0.395374</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2.448263</td>\n",
       "      <td>0.385391</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2.416360</td>\n",
       "      <td>0.391678</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>2.466007</td>\n",
       "      <td>0.384359</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2.410674</td>\n",
       "      <td>0.391943</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>2.380073</td>\n",
       "      <td>0.390274</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>2.423204</td>\n",
       "      <td>0.386939</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>2.341911</td>\n",
       "      <td>0.392923</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2.396574</td>\n",
       "      <td>0.388507</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>2.378717</td>\n",
       "      <td>0.389434</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>2.373491</td>\n",
       "      <td>0.400065</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2.318184</td>\n",
       "      <td>0.401213</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2.373687</td>\n",
       "      <td>0.398407</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2.375169</td>\n",
       "      <td>0.392070</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2.386139</td>\n",
       "      <td>0.398009</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2.370824</td>\n",
       "      <td>0.392153</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2.385119</td>\n",
       "      <td>0.388709</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2.389208</td>\n",
       "      <td>0.397531</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2.346567</td>\n",
       "      <td>0.401646</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2.391705</td>\n",
       "      <td>0.395423</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2.335717</td>\n",
       "      <td>0.399811</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2.379654</td>\n",
       "      <td>0.397229</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2.358512</td>\n",
       "      <td>0.397898</td>\n",
       "      <td>0.980702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               C      gamma     score\n",
       "0       0.015625   0.000015  0.627403\n",
       "1      32.000000   0.031250  0.977193\n",
       "2   65536.000000  64.000000  0.630911\n",
       "3   65536.000000   0.000015  0.975439\n",
       "4   55726.768343   0.002002  0.957879\n",
       "5       0.015625  64.000000  0.627403\n",
       "6    1139.910900   0.000109  0.964912\n",
       "7   65536.000000   0.000196  0.970175\n",
       "8     245.293265   0.001639  0.970160\n",
       "9   65536.000000   0.000015  0.975439\n",
       "10   2588.020664   0.000015  0.950831\n",
       "11      0.015625   0.031601  0.627403\n",
       "12    836.440299   0.009000  0.973684\n",
       "13     20.001983  64.000000  0.630911\n",
       "14    289.796079   0.004175  0.973684\n",
       "15    108.830389   0.026219  0.973684\n",
       "16   5148.186753   0.000646  0.971930\n",
       "17     67.349946   0.007772  0.973684\n",
       "18    105.806104   0.014131  0.971930\n",
       "19  65536.000000   0.000042  0.973684\n",
       "20    136.361171   0.014789  0.973684\n",
       "21   1341.848828   0.001929  0.973684\n",
       "22     19.188037   0.000015  0.627403\n",
       "23  12663.824966   0.000047  0.973684\n",
       "24  65536.000000   0.109173  0.964881\n",
       "25   9220.983302   0.052436  0.956109\n",
       "26   3612.609660   0.000157  0.973684\n",
       "27     39.023960   0.022473  0.975439\n",
       "28  65536.000000   0.025327  0.959634\n",
       "29  24212.033530   0.000015  0.970160\n",
       "..           ...        ...       ...\n",
       "70      2.495015   0.384285  0.980702\n",
       "71      2.505270   0.385631  0.980702\n",
       "72      2.429467   0.394208  0.980702\n",
       "73      2.423513   0.394122  0.980702\n",
       "74      2.403212   0.388294  0.980702\n",
       "75      2.393544   0.395983  0.980702\n",
       "76      2.475230   0.387386  0.980702\n",
       "77      2.419199   0.395374  0.980702\n",
       "78      2.448263   0.385391  0.980702\n",
       "79      2.416360   0.391678  0.980702\n",
       "80      2.466007   0.384359  0.980702\n",
       "81      2.410674   0.391943  0.980702\n",
       "82      2.380073   0.390274  0.980702\n",
       "83      2.423204   0.386939  0.980702\n",
       "84      2.341911   0.392923  0.980702\n",
       "85      2.396574   0.388507  0.980702\n",
       "86      2.378717   0.389434  0.980702\n",
       "87      2.373491   0.400065  0.980702\n",
       "88      2.318184   0.401213  0.980702\n",
       "89      2.373687   0.398407  0.980702\n",
       "90      2.375169   0.392070  0.980702\n",
       "91      2.386139   0.398009  0.980702\n",
       "92      2.370824   0.392153  0.980702\n",
       "93      2.385119   0.388709  0.980702\n",
       "94      2.389208   0.397531  0.980702\n",
       "95      2.346567   0.401646  0.980702\n",
       "96      2.391705   0.395423  0.980702\n",
       "97      2.335717   0.399811  0.980702\n",
       "98      2.379654   0.397229  0.980702\n",
       "99      2.358512   0.397898  0.980702\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "sx = MinMaxScaler()\n",
    "dt = datasets.load_breast_cancer()\n",
    "x = sx.fit_transform(dt.data)\n",
    "y = dt.target\n",
    "\n",
    "ParaSpace = {'C':     {'Type': 'continuous', 'Range': [-6, 16], 'Wrapper': np.exp2}, \n",
    "             'gamma': {'Type': 'continuous', 'Range': [-16, 6], 'Wrapper': np.exp2}}\n",
    "\n",
    "estimator = svm.SVC()\n",
    "score_metric = make_scorer(accuracy_score, True)\n",
    "cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "clf = GPEISklearn(estimator, cv, ParaSpace, max_runs = 100, time_out = 10, refit = True, verbose = True)\n",
    "clf.fit(x, y)\n",
    "clf.logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A contour plot based on a thorough grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_num = 25\n",
    "xlist = np.linspace(-6, 16, grid_num)\n",
    "ylist = np.linspace(-16, 6, grid_num)\n",
    "X, Y = np.meshgrid(xlist, ylist)\n",
    "Z = np.zeros((grid_num,grid_num))\n",
    "for i, C in enumerate(xlist):\n",
    "    for j, gamma in enumerate(ylist):\n",
    "        estimator = svm.SVC(C=2**C,gamma = 2**gamma)\n",
    "        out = cross_val_score(estimator, x, y, cv = cv, scoring = score_metric)\n",
    "        Z[j,i] = np.mean(out)\n",
    "        \n",
    "levels = [0.2, 0.4, 0.8, 0.9, 0.92, 0.94, 0.96, 0.98, 1.0]\n",
    "cp = plt.contourf(X, Y, Z, levels)\n",
    "plt.colorbar(cp)\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('gamma')\n",
    "plt.scatter(np.log2(clf.logs.loc[:,['C']]), \n",
    "            np.log2(clf.logs.loc[:,['gamma']]), color = \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Xgboost for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "dt = datasets.load_diabetes()\n",
    "sx = MinMaxScaler()\n",
    "x = sx.fit_transform(dt.data)\n",
    "y = dt.target\n",
    "\n",
    "ParaSpace = {'booster':          {'Type': 'categorical', 'Mapping': ['gbtree', 'gblinear']},\n",
    "             'max_depth':        {'Type': 'integer',     'Mapping': np.linspace(2,10,9)}, \n",
    "             'n_estimators':     {'Type': 'integer',     'Mapping': np.linspace(100,500,401)},\n",
    "             'min_child_weight': {'Type': 'integer',     'Mapping': np.linspace(1,100,100)},\n",
    "             'subsample':        {'Type': 'continuous',  'Range': [0, 1],  'Wrapper': lambda x:x},\n",
    "             'colsample_bytree': {'Type': 'continuous',  'Range': [0, 1],  'Wrapper': lambda x:x},\n",
    "             'learning_rate':    {'Type': 'continuous',  'Range': [-5, 1], 'Wrapper': np.exp2},\n",
    "             'gamma':            {'Type': 'continuous',  'Range': [-5, 1], 'Wrapper': np.exp2},\n",
    "             'reg_lambda':       {'Type': 'continuous',  'Range': [-5, 1], 'Wrapper': np.exp2},\n",
    "             'reg_lpha':         {'Type': 'continuous',  'Range': [-5, 1], 'Wrapper': np.exp2}}\n",
    "\n",
    "estimator = xgb.XGBRegressor()\n",
    "score_metric = make_scorer(mean_squared_error, False)\n",
    "cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "clf = GPEISklearn(estimator, cv, ParaSpace, max_runs = 100, scoring = score_metric, time_out = 30, refit = True, verbose = True)\n",
    "clf.fit(x, y)\n",
    "clf.logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Example 3: Kmeans for Unsupervised Clustering  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sx = MinMaxScaler()\n",
    "dt = datasets.load_iris()\n",
    "x = sx.fit_transform(dt.data)\n",
    "y = dt.target.reshape([-1,1])\n",
    "\n",
    "ParaSpace = {'n_clusters':  {'Type': 'integer',    'Mapping': np.linspace(2,9,8)}, \n",
    "             'tol':         {'Type': 'continuous', 'Range': [-6, -3], 'Wrapper': exp10}}\n",
    "\n",
    "estimator = KMeans()\n",
    "cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "\n",
    "clf = GPEISklearn(estimator, cv, ParaSpace, max_runs = 100, refit = True, verbose = True)\n",
    "clf.fit(x, y)\n",
    "clf.logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
